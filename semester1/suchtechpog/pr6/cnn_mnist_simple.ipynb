{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWuN2AsMh-pJ"
      },
      "source": [
        "## Сучасні технології програмування в системах зі штучним інтелектом. Практична робота 6. **Робота згорткової нейронної мережі (CNN) у Tensorflow**\n",
        "## Виконав студент групи ШІДМ-51 Тертишний Владислав"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGs8-5wSoI7c"
      },
      "source": [
        "## Convolution (вбудований фільтр)\n",
        "\n",
        "Знайшовши ці важливі функції, ми можемо залишити небажані пікселі без шкоди для якості результату. За допомогою цього методу ми можемо надати моделі людський рівень розпізнавання зображення в реальному світі. Отже, для цього ми маємо згортку.\n",
        "\n",
        "Згортка є найбільш заплутаною та найскладнішою темою в Інтернеті, але це просто пошук зображення шляхом ковзання фільтра (ядра) по зображенню, щоб знайти різні функції зображення. Ядра — це просто двовимірні матриці з різними вагами в них. По суті, це ядро ​​передаватиме зображення, замінюючи значення пікселів середнім значенням суми його ваги у відповідній частині зображення. Ці ядра — чудовий спосіб знайти найважливіші функції зображення."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK6AF7u7ojmh"
      },
      "source": [
        "Ми застосуємо кілька випадково згенерованих ядер до зображення, щоб знайти багато різних функцій зображень  \n",
        "\n",
        "Тож після застосування цього шару згортки до нашої моделі нам потрібно об’єднати функції.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHBOMLg_sk3e"
      },
      "source": [
        "Завантажимо набор зображень рукописних цифр MNIST.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xww3FVUUsv_D",
        "outputId": "53cbb3e6-dc04-4213-ffe6-7b2bf19d67b0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# Plotting random images from dataset\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import random\n",
        "# plt.figure(figsize = (12,5))\n",
        "# for i in range(8):\n",
        "# ind = random.randint(0, len(X_train))\n",
        "# plt.subplot(240+1+i)\n",
        "# plt.imshow(X_train[ind], cmap=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45twfNtt0hrE"
      },
      "source": [
        "Виконаємо попередньу обробку зображень: приведення елементів масиву, які відповідають кожному пікселу зображення, до формату float32 та перекодування елементів масиву з діапазону 0-255 к діапазону 0-1.\n",
        "\n",
        "Мітки зображень перетворюємо в категоріальний вигляд."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "45tMpgICs3Y8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# convert image datatype from integers to floats\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalising piel values\n",
        "X_train = X_train/255.0\n",
        "X_test = X_test/255.0\n",
        "\n",
        "# reshape images to add channel dimension\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93NaJ4fTtqm7",
        "outputId": "5a89dff4-03da-4af2-97d1-6ed951e9da8a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Layer 1\n",
        "# Conv 1\n",
        "model.add(Conv2D(filters=6, kernel_size=(5, 5), strides=1, activation = 'relu', input_shape = (28,28,1)))\n",
        "# Pooling 1\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\n",
        "\n",
        "# Layer 2\n",
        "# Conv 2\n",
        "model.add(Conv2D(filters=16, kernel_size=(5, 5), strides=1, activation='relu'))\n",
        "# Pooling 2\n",
        "model.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
        "\n",
        "# Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "# Layer 3\n",
        "# Fully connected layer 1\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "#Layer 4\n",
        "#Fully connected layer 2\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "#Layer 5\n",
        "#Output Layer\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 512\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
        "\t\t\t\t\tsteps_per_epoch=X_train.shape[0]//batch_size,\n",
        "\t\t\t\t\tvalidation_data=(X_test, y_test),\n",
        "\t\t\t\t\tvalidation_steps=X_test.shape[0]//batch_size, verbose = 0 )\n",
        "\n",
        "_, acc = model.evaluate(X_test, y_test, verbose = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgTv-VnV2pLP"
      },
      "source": [
        "## **Завдання**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEXecAaz2ukJ"
      },
      "source": [
        "\n",
        "\n",
        "1.   Перевірити, як впливаєна час і результати навчання моделі кількість епох навчання\n",
        "2.  Дослідити, як змінить хід і результати навчання зміна кількості нейронів в щільних та конволюційних шарах.\n",
        "3.   Додати один, а потім два конволюційні блоки, також дослідити якість навчання моделі.\n",
        "4.   Побудувати аналогічний класифікатор для набору даних Fashion MNIST з попередньої роботи.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Завдання 1: Вплив кількості епох на навчання\n",
            "Епохи: 5, Час: 15.09с, Точність: 0.9809\n",
            "Епохи: 10, Час: 29.73с, Точність: 0.9863\n",
            "Епохи: 20, Час: 58.49с, Точність: 0.9888\n",
            "Епохи: 30, Час: 87.38с, Точність: 0.9901\n",
            "\n",
            "Завдання 2: Вплив кількості нейронів\n",
            "Архітектура {'conv1': 6, 'conv2': 16, 'dense1': 120, 'dense2': 84}: Точність: 0.9887\n",
            "Архітектура {'conv1': 12, 'conv2': 32, 'dense1': 240, 'dense2': 168}: Точність: 0.9921\n",
            "Архітектура {'conv1': 3, 'conv2': 8, 'dense1': 60, 'dense2': 42}: Точність: 0.9826\n",
            "\n",
            "Завдання 3: Додаткові конволюційні блоки\n",
            "Точність з 1 додатковим блоком: 0.9896\n",
            "Точність з 2 додатковими блоками: 0.9877\n",
            "\n",
            "Завдання 4: Fashion MNIST\n",
            "Точність на Fashion MNIST: 0.8786\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Дослідження впливу кількості епох\n",
        "print(\"Завдання 1: Вплив кількості епох на навчання\")\n",
        "epochs_to_test = [5, 10, 20, 30]\n",
        "epoch_results = []\n",
        "\n",
        "for epoch_num in epochs_to_test:\n",
        "    start_time = time.time()\n",
        "    \n",
        "    model = Sequential([\n",
        "        Conv2D(6, (5, 5), activation='relu', input_shape=(28,28,1)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(16, (5, 5), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(120, activation='relu'),\n",
        "        Dense(84, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X_train, y_train,\n",
        "                       epochs=epoch_num,\n",
        "                       batch_size=512,\n",
        "                       validation_data=(X_test, y_test),\n",
        "                       verbose=0)\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    \n",
        "    print(f'Епохи: {epoch_num}, Час: {training_time:.2f}с, Точність: {accuracy:.4f}')\n",
        "    epoch_results.append((epoch_num, training_time, accuracy))\n",
        "\n",
        "# 2. Дослідження різної кількості нейронів\n",
        "print(\"\\nЗавдання 2: Вплив кількості нейронів\")\n",
        "architectures = [\n",
        "    {'conv1': 6, 'conv2': 16, 'dense1': 120, 'dense2': 84},  # Оригінальна\n",
        "    {'conv1': 12, 'conv2': 32, 'dense1': 240, 'dense2': 168},  # Збільшена\n",
        "    {'conv1': 3, 'conv2': 8, 'dense1': 60, 'dense2': 42}  # Зменшена\n",
        "]\n",
        "\n",
        "for arch in architectures:\n",
        "    model = Sequential([\n",
        "        Conv2D(arch['conv1'], (5, 5), activation='relu', input_shape=(28,28,1)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(arch['conv2'], (5, 5), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(arch['dense1'], activation='relu'),\n",
        "        Dense(arch['dense2'], activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    history = model.fit(X_train, y_train,\n",
        "                       epochs=20,\n",
        "                       batch_size=512,\n",
        "                       validation_data=(X_test, y_test),\n",
        "                       verbose=0)\n",
        "    \n",
        "    _, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f'Архітектура {arch}: Точність: {accuracy:.4f}')\n",
        "\n",
        "# 3. Додавання конволюційних блоків\n",
        "print(\"\\nЗавдання 3: Додаткові конволюційні блоки\")\n",
        "\n",
        "# Модель з одним додатковим блоком\n",
        "model_extra1 = Sequential([\n",
        "    Conv2D(6, (5, 5), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(16, (5, 5), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
        "    Flatten(),\n",
        "    Dense(120, activation='relu'),\n",
        "    Dense(84, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_extra1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history1 = model_extra1.fit(X_train, y_train, epochs=20, batch_size=512, \n",
        "                           validation_data=(X_test, y_test), verbose=0)\n",
        "_, acc1 = model_extra1.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Точність з 1 додатковим блоком: {acc1:.4f}')\n",
        "\n",
        "# Модель з двома додатковими блоками\n",
        "model_extra2 = Sequential([\n",
        "    Conv2D(6, (5, 5), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(16, (5, 5), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
        "    Flatten(),\n",
        "    Dense(120, activation='relu'),\n",
        "    Dense(84, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_extra2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history2 = model_extra2.fit(X_train, y_train, epochs=20, batch_size=512, \n",
        "                           validation_data=(X_test, y_test), verbose=0)\n",
        "_, acc2 = model_extra2.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Точність з 2 додатковими блоками: {acc2:.4f}')\n",
        "\n",
        "# 4. Fashion MNIST\n",
        "print(\"\\nЗавдання 4: Fashion MNIST\")\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train_fashion, y_train_fashion), (X_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
        "\n",
        "# Попередня обробка даних\n",
        "X_train_fashion = X_train_fashion.astype('float32') / 255.0\n",
        "X_test_fashion = X_test_fashion.astype('float32') / 255.0\n",
        "\n",
        "X_train_fashion = X_train_fashion.reshape(X_train_fashion.shape[0], 28, 28, 1)\n",
        "X_test_fashion = X_test_fashion.reshape(X_test_fashion.shape[0], 28, 28, 1)\n",
        "\n",
        "y_train_fashion = to_categorical(y_train_fashion)\n",
        "y_test_fashion = to_categorical(y_test_fashion)\n",
        "\n",
        "# Створення та навчання моделі для Fashion MNIST\n",
        "model_fashion = Sequential([\n",
        "    Conv2D(6, (5, 5), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(16, (5, 5), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(120, activation='relu'),\n",
        "    Dense(84, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_fashion.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_fashion = model_fashion.fit(X_train_fashion, y_train_fashion,\n",
        "                                  epochs=20,\n",
        "                                  batch_size=512,\n",
        "                                  validation_data=(X_test_fashion, y_test_fashion),\n",
        "                                  verbose=0)\n",
        "\n",
        "_, accuracy_fashion = model_fashion.evaluate(X_test_fashion, y_test_fashion, verbose=0)\n",
        "print(f'Точність на Fashion MNIST: {accuracy_fashion:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "На основі отриманих результатів можна зробити наступні висновки:\n",
        "\n",
        "1. **Вплив кількості епох на навчання:**\n",
        "- Спостерігається стабільне покращення точності зі збільшенням кількості епох: від 0.9809 (5 епох) до 0.9901 (30 епох)\n",
        "- Однак приріст точності сповільнюється: між 5 і 10 епохами різниця складає 0.0054, тоді як між 20 і 30 епохами лише 0.0013\n",
        "- Час навчання зростає лінійно з кількістю епох\n",
        "- Оптимальним балансом між часом навчання та точністю можна вважати 20 епох, так як подальше збільшення дає незначний приріст точності при суттєвому збільшенні часу навчання\n",
        "\n",
        "2. **Вплив кількості нейронів:**\n",
        "- Збільшена архітектура (12-32-240-168) показала найкращий результат з точністю 0.9921\n",
        "- Зменшена архітектура (3-8-60-42) показала найгірший результат - 0.9826\n",
        "- Різниця між найкращою та найгіршою архітектурою складає близько 0.01, що свідчить про достатню робастність моделі\n",
        "- Оригінальна архітектура (6-16-120-84) показала збалансований результат 0.9887\n",
        "\n",
        "3. **Вплив додаткових конволюційних блоків:**\n",
        "- Додавання одного конволюційного блоку дещо покращило точність до 0.9896\n",
        "- Додавання другого блоку призвело до незначного погіршення результату (0.9877)\n",
        "- Це може свідчити про появу перенавчання при надмірному ускладненні архітектури\n",
        "\n",
        "4. **Порівняння з Fashion MNIST:**\n",
        "- Точність на Fashion MNIST (0.8786) значно нижча ніж на звичайному MNIST\n",
        "- Це очікуваний результат, оскільки Fashion MNIST є складнішим набором даних з більшою варіативністю об'єктів\n",
        "- Різниця в точності складає приблизно 0.11, що відображає більшу складність класифікації одягу порівняно з цифрами\n",
        "\n",
        "**Загальні висновки:**\n",
        "1. Модель показує високу ефективність на наборі MNIST, досягаючи точності понад 99%\n",
        "2. Оптимальна конфігурація включає:\n",
        "   - 20 епох навчання\n",
        "   - Збільшену кількість нейронів\n",
        "   - Один додатковий конволюційний блок\n",
        "3. Подальше ускладнення архітектури або збільшення кількості епох дає незначний приріст продуктивності\n",
        "4. Модель демонструє достатню гнучкість для роботи з різними наборами даних, хоча ефективність залежить від складності задачі\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
